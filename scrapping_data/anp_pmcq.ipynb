{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mfelipemota/Projects/olho-no-combustivel/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas polars bs4 requests \n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import bs4\n",
    "import requests\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all links that contains .csv \n",
    "relative_path = './pmqc/'\n",
    "url = 'https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/pmqc-programa-de-monitoramento-da-qualidade-dos-combustiveis'\n",
    "response = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.find_all('a', href=re.compile(r'.csv'))\n",
    "# get only links between href and \" target\n",
    "links = [link['href'] for link in links if 'target' in link.attrs]\n",
    "\n",
    "# # download all files using multiprocessing and urllib\n",
    "import urllib.request\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def download_file(link):\n",
    "    # from string https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/pmqc/2023/pmqc_2023_04.csv\n",
    "    # get year of file \n",
    "    year = link.split('/')[-2]\n",
    "    name_file = link.split('/')[-1]\n",
    "    if not os.path.exists(f\"./pmqc/\"):\n",
    "        os.makedirs(f\"./pmqc/\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(link, f\"./pmqc/{name_file}\")\n",
    "        print(f\"Downloaded {name_file}\")\n",
    "    except:\n",
    "        print(f\"Error to download {name_file}\")\n",
    "        pass\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Enviar as tarefas para o executor\n",
    "    futures = [executor.submit(download_file, link) for link in links]\n",
    "\n",
    "    # Iterar sobre os resultados à medida que são concluídos\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            # Aqui você pode lidar com o resultado, se necessário\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_destination = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5198959, 19)\n",
      "['DataColeta', 'IdNumeric', 'GrupoProduto', 'Produto', 'RazaoSocialPosto', 'CnpjPosto', 'Distribuidora', 'Endereço', 'Complemento', 'Bairro', 'Município', 'Latitude', 'Longitude', 'Uf', 'RegiaoPolitica', 'Ensaio', 'Resultado', 'UnidadeEnsaio', 'Conforme']\n",
      "CPU times: user 6.44 s, sys: 1.72 s, total: 8.17 s\n",
      "Wall time: 2.98 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19037, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "if not os.path.exists(f\"pmqc_processed/\"):\n",
    "    os.makedirs(f\"pmqc_processed/\")\n",
    "    \n",
    "df = pl.read_csv(\"pmqc/*.csv\", separator=';', infer_schema_length=10000, ignore_errors=True, truncate_ragged_lines=True)#.limit(1000)\n",
    "df = df.with_columns(\n",
    "    pl.col('DataColeta').str.strptime(pl.Date, \"%Y-%m-%d\", strict=False).cast(pl.Date),\n",
    "    # remove all special characters from column CnpjMatriz\n",
    "    pl.col('CnpjPosto').str.replace_all(r'[^0-9]', '')\n",
    ")\n",
    "## print count rows\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "#postos = postos.unique(subset=[\"CnpjPosto\"])\n",
    "\n",
    "# # ## generate postos dimensions\n",
    "postos = df.select([\n",
    "    'CnpjPosto',\n",
    "    'RazaoSocialPosto',\n",
    "    'Distribuidora',\n",
    "    'DataColeta',\n",
    "    'Endereço',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'Bairro',\n",
    "    'Município',\n",
    "    'Uf'])\n",
    "postos = postos.with_columns(\n",
    "    pl.col('CnpjPosto').str.slice(0, 8).cast(pl.Int32).alias('CnpjMatriz')\n",
    ")\n",
    "\n",
    "postos = postos.sort('DataColeta', descending=True).unique(subset=[\"CnpjPosto\"], keep='first')\n",
    "# create empty dataframe with date (timestamp), cnpj, observation_txt\n",
    "df_errors = []\n",
    "\n",
    "# for each row if latitude or longitude is null, add row to df_errors\n",
    "for row in postos.rows(named=True):\n",
    "    if row['Latitude'] is None or row['Longitude'] is None:\n",
    "        df_errors.append({\n",
    "            'DataColeta': row['DataColeta'],\n",
    "            'CnpjPosto': row['CnpjPosto'],\n",
    "            'Observação': 'Latitude ou Longitude não informados'\n",
    "        })\n",
    "\n",
    "df_errors = pd.DataFrame(df_errors)\n",
    "df_errors = pl.from_pandas(df_errors)\n",
    "df_errors.shape\n",
    "\n",
    "# remove all rows with latitude or longitude is null\n",
    "\n",
    "# # apply function to get new column \"geometry\" with values like {'type': 'Point', 'coordinates': [-54.61611004, -20.46871167]}} in string format\n",
    "\n",
    "# def get_geometry(row):\n",
    "#     if row['Longitude'] is None or row['Latitude'] is None:\n",
    "#         return {'type': 'Point', 'coordinates': [0, 0]}  # You can use any default values here\n",
    "#     return {'type': 'Point', 'coordinates': [row['Longitude'], row['Latitude']]}\n",
    "\n",
    "# postos = postos.with_columns(\n",
    "#     pl.struct(\n",
    "#         pl.col('Longitude'),\n",
    "#         pl.col('Latitude')\n",
    "#     ).apply(get_geometry).alias('geometry')\n",
    "# )\n",
    "\n",
    "# print(postos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# generate fact table\n",
    "coletas = df.select([\n",
    "    'DataColeta',\n",
    "    'IdNumeric',\n",
    "    'CnpjPosto',\n",
    "    'Produto',\n",
    "    'Ensaio',\n",
    "    'Resultado',\n",
    "    'UnidadeEnsaio',\n",
    "    'Conforme'])\n",
    "coletas = coletas.unique(subset=['IdNumeric'])\n",
    "# get only postos in postos dataframe\n",
    "coletas = coletas.join(postos, on='CnpjPosto', how='inner')\n",
    "\n",
    "coletas.write_json('pmqc_processed/coletas.json', row_oriented=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert postos to MongoDB with column CnpjMatriz as index, and latitute and longitude as 2dsphere\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "MONGO_PORT = 27017\n",
    "MONGO_HOST = \"localhost\"\n",
    "MONGO_PASS = \"example\"\n",
    "MONGO_USER = \"root\"\n",
    "MONGO_URL = \"mongodb://root:example@localhost:27017\"\n",
    "\n",
    "client = MongoClient(MONGO_URL)\n",
    "db = client['pmqc']\n",
    "collection = db['postos']\n",
    "collection.create_index('CnpjPosto', unique=True)\n",
    "collection.create_index([('geometry', '2dsphere')])\n",
    " \n",
    "\n",
    "# transform json to latitude and longitude to column geometry as 2dsphere\n",
    "with open('pmqc_processed/postos.json') as f:\n",
    "    data = json.load(f)\n",
    "    collection.insert_many(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert coletas to MongoDB\n",
    "collection = db['coletas']\n",
    "collection.create_index('IdNumeric', unique=True)\n",
    "with open('pmqc_processed/coletas.json') as f:\n",
    "    data = json.load(f)\n",
    "    collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count rows\n",
    "collection.count_documents({})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olhonocomb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
